# Backend Configuration
BACKEND_HOST=0.0.0.0
BACKEND_PORT=8000
PYTHONUNBUFFERED=1

# Ollama Configuration
OLLAMA_HOST=http://ollama:11434
OLLAMA_MODEL=mistral  # or llama2, neural-chat, etc.

# Vector Database Configuration
CHROMA_DB_PATH=/app/data/chroma

# Frontend Configuration
FRONTEND_PORT=3000
VITE_API_URL=http://localhost:8000

# Application Configuration
DEBUG=false
LOG_LEVEL=INFO
